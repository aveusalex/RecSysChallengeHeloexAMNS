{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importando dados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('../data/evaluation/eval_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   user_id      1000 non-null   object\n",
      " 1   user_perfil  1000 non-null   object\n",
      " 2   gt_reclist   1000 non-null   object\n",
      " 3   reclist      1000 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "eval_df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                  user_id             user_perfil  \\\n0  -1BSu2dt_rOAqllw9ZDXtA  5XsC0tB8chKjTIW7mU6TnQ   \n1  -6DoXmdXEy_P5N-QZzntgA  Ifw5wqcChnL4zBigtR7NKA   \n2  -8NOuak4Sipn7-zy7Nk5hg  OKPUO8zvBBL-OA6-SfDx8Q   \n3  -8rSnT5ztVk6vmTDkxTqsQ  VSjoo6kJ9MU4G0cfO_-CRA   \n4  -C7xxeVQI5qEZGAzFdx-cg  rXqlpCH6z9rSFNCL76FfLw   \n\n                                          gt_reclist  \\\n0  ['5XsC0tB8chKjTIW7mU6TnQ', 'wn4U347OALm5H0MOBR...   \n1  ['Ifw5wqcChnL4zBigtR7NKA', 'v1GCQz7ZsntWI-GlGP...   \n2  ['OKPUO8zvBBL-OA6-SfDx8Q', 'OHplb2m_dKPXY46mS0...   \n3  ['VSjoo6kJ9MU4G0cfO_-CRA', 'DH-vk-XzWMT9rRLcbB...   \n4  ['rXqlpCH6z9rSFNCL76FfLw', 'WY_dcOTyRA-AgksCXi...   \n\n                                             reclist  \n0  ['XTIc2pKNdmmvX60lIHV0OQ', 'GyvtAyCurqFGovXp-t...  \n1  ['QB0NhiW--2rje9Fr1ek2eA', 'o4IiNbNybcy-L4vzTS...  \n2  ['M6yUUIE8-incodeeJrMpVQ', 'fw6PlWy2ghCzuUH24p...  \n3  ['3zK9LTY3TgH7nU18-dnXtA', 'DH-vk-XzWMT9rRLcbB...  \n4  ['6aDmYbqNKeWn9tynvFQa-w', 'nMHM74eFQuJyS_a7EV...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>user_perfil</th>\n      <th>gt_reclist</th>\n      <th>reclist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1BSu2dt_rOAqllw9ZDXtA</td>\n      <td>5XsC0tB8chKjTIW7mU6TnQ</td>\n      <td>['5XsC0tB8chKjTIW7mU6TnQ', 'wn4U347OALm5H0MOBR...</td>\n      <td>['XTIc2pKNdmmvX60lIHV0OQ', 'GyvtAyCurqFGovXp-t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-6DoXmdXEy_P5N-QZzntgA</td>\n      <td>Ifw5wqcChnL4zBigtR7NKA</td>\n      <td>['Ifw5wqcChnL4zBigtR7NKA', 'v1GCQz7ZsntWI-GlGP...</td>\n      <td>['QB0NhiW--2rje9Fr1ek2eA', 'o4IiNbNybcy-L4vzTS...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-8NOuak4Sipn7-zy7Nk5hg</td>\n      <td>OKPUO8zvBBL-OA6-SfDx8Q</td>\n      <td>['OKPUO8zvBBL-OA6-SfDx8Q', 'OHplb2m_dKPXY46mS0...</td>\n      <td>['M6yUUIE8-incodeeJrMpVQ', 'fw6PlWy2ghCzuUH24p...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-8rSnT5ztVk6vmTDkxTqsQ</td>\n      <td>VSjoo6kJ9MU4G0cfO_-CRA</td>\n      <td>['VSjoo6kJ9MU4G0cfO_-CRA', 'DH-vk-XzWMT9rRLcbB...</td>\n      <td>['3zK9LTY3TgH7nU18-dnXtA', 'DH-vk-XzWMT9rRLcbB...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-C7xxeVQI5qEZGAzFdx-cg</td>\n      <td>rXqlpCH6z9rSFNCL76FfLw</td>\n      <td>['rXqlpCH6z9rSFNCL76FfLw', 'WY_dcOTyRA-AgksCXi...</td>\n      <td>['6aDmYbqNKeWn9tynvFQa-w', 'nMHM74eFQuJyS_a7EV...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Sabemos que:\n",
    "- User_id : é o id do usuário\n",
    "- user_perfil: é o id do business que a pessoa melhor avaliou\n",
    "- gt_reclist: business que a pessoa avaliou com 4 ou 5 estrelas\n",
    "- rec_list: business selecionados aleatoriamente + os business de gt_reclist -> devemos ordenar essa lista."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-> A ideia é criarmos os embeddings somente para os business que estão em gt_reclist e rec_list e para os usuários selecionados."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Separando os usuários que estão no dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "users = eval_df['user_id'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(1000,)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-> Para esses usuários, vamos gerar embeddings de suas avaliações e de seus perfis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# carregando os dados de users\n",
    "users_df = pd.read_parquet('../data/DatasetsLimpos/yelp_academic_dataset_user.parquet')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1987897 entries, 0 to 1987896\n",
      "Data columns (total 19 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   user_id             object \n",
      " 1   review_count        float32\n",
      " 2   useful              float32\n",
      " 3   funny               float32\n",
      " 4   cool                float32\n",
      " 5   fans                float32\n",
      " 6   compliment_hot      float32\n",
      " 7   compliment_more     float32\n",
      " 8   compliment_profile  float32\n",
      " 9   compliment_cute     float32\n",
      " 10  compliment_list     float32\n",
      " 11  compliment_note     float32\n",
      " 12  compliment_plain    float32\n",
      " 13  compliment_cool     float32\n",
      " 14  compliment_funny    float32\n",
      " 15  compliment_writer   float32\n",
      " 16  compliment_photos   float32\n",
      " 17  account_age         int64  \n",
      " 18  chato               float32\n",
      "dtypes: float32(17), int64(1), object(1)\n",
      "memory usage: 159.2+ MB\n"
     ]
    }
   ],
   "source": [
    "users_df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gerando os embeddings de seus reviews"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df_reviews = pd.read_parquet('../data/DatasetsLimpos/yelp_academic_dataset_review.parquet')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6990280 entries, 0 to 6990279\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Dtype \n",
      "---  ------       ----- \n",
      " 0   user_id      object\n",
      " 1   business_id  object\n",
      " 2   stars        uint8 \n",
      " 3   useful       int32 \n",
      " 4   funny        int32 \n",
      " 5   cool         int32 \n",
      " 6   text         object\n",
      "dtypes: int32(3), object(3), uint8(1)\n",
      "memory usage: 246.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_reviews.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# filtrando apenas os reviews dos usuários selecionados\n",
    "df_reviews = df_reviews[df_reviews['user_id'].isin(users)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(13758, 7)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "1000"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.user_id.nunique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# agrupando os reviews por usuário\n",
    "df_reviews_text = df_reviews[['user_id', 'text']].groupby('user_id').agg(lambda x: list(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                     text\nuser_id                                                                  \n-1BSu2dt_rOAqllw9ZDXtA  [Hank and I love Brocatos!The freshest ingredi...\n-6DoXmdXEy_P5N-QZzntgA  [We stopped in for breakfast burritos one morn...\n-8NOuak4Sipn7-zy7Nk5hg  [One of Philadelphia's best restaurants in my ...\n-8rSnT5ztVk6vmTDkxTqsQ  [PROS\\nYelp deal - use BOGO 50% entree\\nOxtail...\n-C7xxeVQI5qEZGAzFdx-cg  [This place is the best! Their food isn't spic...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>-1BSu2dt_rOAqllw9ZDXtA</th>\n      <td>[Hank and I love Brocatos!The freshest ingredi...</td>\n    </tr>\n    <tr>\n      <th>-6DoXmdXEy_P5N-QZzntgA</th>\n      <td>[We stopped in for breakfast burritos one morn...</td>\n    </tr>\n    <tr>\n      <th>-8NOuak4Sipn7-zy7Nk5hg</th>\n      <td>[One of Philadelphia's best restaurants in my ...</td>\n    </tr>\n    <tr>\n      <th>-8rSnT5ztVk6vmTDkxTqsQ</th>\n      <td>[PROS\\nYelp deal - use BOGO 50% entree\\nOxtail...</td>\n    </tr>\n    <tr>\n      <th>-C7xxeVQI5qEZGAzFdx-cg</th>\n      <td>[This place is the best! Their food isn't spic...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews_text.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# criando coluna quantidade de reviews\n",
    "df_reviews_text['qtd_reviews'] = df_reviews_text['text'].apply(lambda x: len(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "count    1000.000000\nmean       13.758000\nstd         4.122673\nmin        10.000000\n25%        11.000000\n50%        12.000000\n75%        15.000000\nmax        35.000000\nName: qtd_reviews, dtype: float64"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews_text.qtd_reviews.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Boa parte dos usuários selecionados tem menos de 15 reviews. Mas é um número bacana já para termos em mente seu comportamento."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gerando os embeddings com o BERT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import time\n",
    "\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_bert_embedding(text_list):\n",
    "    # if text_list is over than 15 items, split it in groups of 15\n",
    "    # print(len(text_list))\n",
    "    if len(text_list) > 15:\n",
    "        # print(\"Text list is over than 15 items, split it in groups of 15\")\n",
    "        text_list = [text_list[i:i + 15] for i in range(0, len(text_list), 15)]\n",
    "    else:\n",
    "        text_list = [text_list]\n",
    "    embs = []\n",
    "    for text in text_list:\n",
    "        start = time.time()\n",
    "        tokens = []\n",
    "        # clip text if it is too long (more than 512 tokens)\n",
    "        for idx in range(len(text)):\n",
    "            if len(text[idx]) > 512:\n",
    "                text[idx] = text[idx][:510]\n",
    "            # Add the special tokens.\n",
    "            marked_text = \"[CLS] \" + text[idx] + \" [SEP]\"\n",
    "            # Split the sentence into tokens.\n",
    "            tokenized_text = tokenizer.tokenize(marked_text)\n",
    "            # padding if text is less than 512 tokens\n",
    "            if len(tokenized_text) < 512:\n",
    "                tokenized_text = tokenized_text + [\"[PAD]\"] * (512 - len(tokenized_text))\n",
    "            # Map the token strings to their vocabulary indexes.\n",
    "            indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "            tokens.append(indexed_tokens)\n",
    "        # Convert inputs to PyTorch tensors\n",
    "        tokens_tensor = torch.tensor(tokens)\n",
    "\n",
    "        # Put the model in \"evaluation\" mode,meaning feed-forward operation.\n",
    "        model.eval()\n",
    "        # Run the text through BERT, and collect all the hidden states produced from all 12 layers.\n",
    "        with torch.no_grad():\n",
    "            outputs = model(tokens_tensor)[2][-4:]\n",
    "\n",
    "        # sum of last four layer\n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        outputs = outputs.sum(1)\n",
    "        # mean of the tokens, results in one vector of 768 dimensions per text\n",
    "        outputs = torch.mean(outputs, 1).squeeze(0).numpy()\n",
    "        print(\"Time to get embedding: \", time.time() - start)\n",
    "        embs.append(outputs)\n",
    "    return embs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# aplicando no dataframe\n",
    "df_reviews_text['bert_embedding'] = df_reviews_text['text'].apply(get_bert_embedding)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
